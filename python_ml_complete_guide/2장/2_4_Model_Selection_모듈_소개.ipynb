{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.4 Model Selection 모듈 소개.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxdeBi10ngMkGX1YL6KVGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwanhong66/TodayILearned/blob/master/python_ml_complete_guide/2%EC%9E%A5/2_4_Model_Selection_%EB%AA%A8%EB%93%88_%EC%86%8C%EA%B0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpunAdKynxle",
        "colab_type": "text"
      },
      "source": [
        "[Book] 파이썬 머신러닝 완벽 가이드\n",
        "- 예제 코드 transcription\n",
        "- 개념, 프로세스, API, Best Practice 등 익히기\n",
        "- 책 예제 코드 github (https://github.com/wikibook/pymldg-rev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWfQPsvn65c",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Model Selection 모듈 소개\n",
        "- sklearn.model_selection 모듈\n",
        "- 학습 데이터와 테스트 데이터 셋 분리: train_test_split\n",
        "- 교차 검증(cross validation) 분할 및 평가: KFold, StratifiedKFold, cross_val_score\n",
        "- Estimator의 하이퍼 파라미터 튜닝: GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shjHx_YToskQ",
        "colab_type": "text"
      },
      "source": [
        "### 학습/테스트 데이터 세트 분리 - train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhT2g3c_np0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eafe9eb8-4da2-4baa-e092-00a68d1ab90a"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 셋으로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU4ZfmsGpsUu",
        "colab_type": "text"
      },
      "source": [
        "- 이미 학습한 데이터 셋으로 예측하였기 때문에, 학습 시 보았던 데이터는 정답을 알고 있음\n",
        "- 예측을 수행하는 데이터 셋은 학습에 사용한 학습용 데이터 셋이 아닌, 별도의 전용 테스트 데이터 셋이어야 함\n",
        "- train_test_split()으로 학습 및 테스트 데이터 셋을 쉽게 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGS5n3KAqWKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \\\n",
        "                                                    test_size=0.3, random_state=121)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBABLhFyq0J-",
        "colab_type": "text"
      },
      "source": [
        "- train_test_split()을 이용해 테스트 데이터 셋을 전체의 30%로, 학습 데이터 셋을 70%로 분리\n",
        "- random_state=121로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "570yiHTyrCez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c07f73d3-1446-4929-c96e-8e839bdb261b"
      },
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZc3KKWbrUXj",
        "colab_type": "text"
      },
      "source": [
        "### 교차 검증\n",
        "- 고정된 학습 데이터와 테스트 데이터로 평가를 하면, 모델이 테스트 데이터에만 최적의 성능을 보이게 편향되어 학습이 될 수 있음\n",
        "- 고정된 테스트 데이터 기준으로 평가를 하여, 해당 성능을 기준으로 모델을 개선하면 보지 못한 다른 테스트 데이터가 들어올 경우, 성능이 저하되는 현상이 나타날 수 있음 (일반화 성능 저하)\n",
        "- 이러한 문제점을 개선하기 위해, 교차 검증으로 다양한 학습과 평가를 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11jfLdoyswsZ",
        "colab_type": "text"
      },
      "source": [
        "#### K 폴드 교차 검증 (K-fold cross validation)\n",
        "\n",
        "- K개의 데이터 fold 셋을 만들어, k번만큼 각 fold 셋에 학습과 검증 평가를 반복적으로 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUaKCeJHsUF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2da9883f-a024-4d38-9962-8d10037a290c"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 fold 셋으로 분리하는 KFold 객체와 fold 셋 별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:', features.shape[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs_nGKAjuIV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2d7d3539-9800-4ea8-b8e6-2a573a99ef43"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split()을 호출하면, fold 별 학습용, 검증용 테스트의 row index를 array로 반환\n",
        "for train_index, test_index, in kfold.split(features):\n",
        "  # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터의 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  # 학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "  # 반복 시마다 정확도 측정\n",
        "  accuracy = np.around(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = y_train.shape[0]\n",
        "  print('#{} 교차 검증 정확도 : {}, 학습 데이터 크기: {}, 검증 데이터 크기: {}'\n",
        "        .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{} 검증 세트 인덱스: {}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration 별, 정확도를 합하여 평균 정확도 계산\n",
        "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1 교차 검증 정확도 : 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 120\n",
            "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "#2 교차 검증 정확도 : 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 120\n",
            "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "#3 교차 검증 정확도 : 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 120\n",
            "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "#4 교차 검증 정확도 : 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 120\n",
            "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "#5 교차 검증 정확도 : 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 120\n",
            "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "## 평균 검증 정확도: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WVw1MuJwAt5",
        "colab_type": "text"
      },
      "source": [
        "- 5번의 교차 검증 결과 평균 검증 정확도는 0.9\n",
        "- 교차 검증 시마다 검증 세트의 인덱스가 달라짐 확인 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N79S0E9uwOBA",
        "colab_type": "text"
      },
      "source": [
        "#### Stratified K-fold \n",
        "- Stratified K-fold은 불균형한(imbalanced) 비율의 label 데이터 집합을 위한 k-fold 방식\n",
        "- 원본 데이터의 label 분포를 고려하여, 비율을 유지하여 학습과 검증 데이터 셋을 분배"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28BiuD6rw1ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "44c550f5-bdb2-4b25-8cd5-5cb1f84c1126"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYRwOTOkxLou",
        "colab_type": "text"
      },
      "source": [
        "- 붓꽃 데이터의 label(품종) 비율은 모두 50개로 동일\n",
        "- KFold에서 이슈가 발생하는 현상 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCCckQHxWIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "8d04f869-d6a3-42e6-da0b-87f65a0cd320"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clHIwLRazQMs",
        "colab_type": "text"
      },
      "source": [
        "- 교차 검증 시마다 3개의 fold 셋으로 만들어지는 학습 label과 검증 label이 다른 값이 추출\n",
        "- 1, 2 label로 학습한 모델은 0 label만 가진 검증 데이터 셋을 예측할 수 없음\n",
        "- StratifiedKFold는 이렇게 KFold로 분할된 label 데이터 셋이 전체 label 값의 분포를 반영하지 못 하는 문제를 해결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMhy9heg0EPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "d2a39333-ef9c-4813-91f3-c15ce301a635"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter = 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AACSRljV03r2",
        "colab_type": "text"
      },
      "source": [
        "- 학습 label과 검증 label의 데이터 값 분포가 동일하게 할당\n",
        "- 전체 label에 대해 학습하고, 검증 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4AwEzEd1DQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5a85de81-8661-40cd-c7be-f868a67cd516"
      },
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "# StratifiedKFold의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  # 학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('#{} 교차 검증 정확도 :{}, 학습 데이터 크기: {}, 검증 데이터 크기: {}'\n",
        "        .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{} 검증 세트 인덱스: {}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 교차 검증별 정확도 및 평균 정확도 계산\n",
        "print('## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스: [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3Nzlm32ndh",
        "colab_type": "text"
      },
      "source": [
        "- 3개의 Stratified K-fold로 교차 검증하여 평균 검증 정확도 약 96.67%\n",
        "- Stratified K-fold는 원본 데이터의 label 분포 특성을 반영하여, 학습 및 검증 데이터 세트를 만듬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTC6z3Lh2-Q4",
        "colab_type": "text"
      },
      "source": [
        "#### 교차 검증을 보다 간편하게 - cross_val_score()\n",
        "- 교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API\n",
        "  * 1) fold 셋을 설정\n",
        "  * 2) 학습 및 검증 데이터 셋의 index 추출하는 iteration\n",
        "  * 3) 반복적으로 학습과 예측 수행하여, 예측 성능 반환\n",
        "- 이러한 일련의 과정을 한번에 수행해주는 API\n",
        "- cross_val_score() 수행 후 반환 값은 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypqyOBr94EQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4b8d580-3320-4639-e31c-f5c97e6d9de1"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbID3RA48p7F",
        "colab_type": "text"
      },
      "source": [
        "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
        "- Classifier나 Regressor와 같은 알고리즘에 사용하는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출\n",
        "- 교차 검증 기반으로 최적의 하이퍼 파라미터 값 찾음\n",
        "  * 데이터 셋을 cross validation을 위한 학습/테스트 셋으로 자동 분할\n",
        "  * parameter grid에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터 찾음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut4Mwyk28jq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_parameters = {'max_depth': [1, 2, 3],\n",
        "                   'min_samples_split': [2, 3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnyTkNLf9fNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpBln_Gb_EzR",
        "colab_type": "text"
      },
      "source": [
        "- train_test_split()으로 학습 데이터와 테스트 데이터 분리\n",
        "- 학습 데이터에서 GridSearchCV를 이용해 최적의 하이퍼 파라미터 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5U7V6RQ_V7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1ea02b98-9ba6-4848-a800-2b16adc1d1dc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
        "### refit=True가 default. True이면 가장 좋은 파라미터 설정으로 재학습\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9dOM9yNAQjQ",
        "colab_type": "text"
      },
      "source": [
        "- 하이퍼 파라미터를 순차적으로 변경하면서 학습 및 평가 수행\n",
        "- params: 학습 및 평가를 수행할 때마다 적용된 개별 하이퍼 파라미터 값\n",
        "- rank_test_score: 하이퍼 파라미터 별로 성능이 좋은 score 순위\n",
        "- mean_test_score: 개별 하이퍼 파라미터 별로 CV의 fold 테스트 세트에 대해 총 수행한 평가 평균값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC3iD7lRA82E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "298345b9-f941-4c93-81c1-80bda5637c9d"
      },
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도:0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsJKL9r-BgRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a4b73ed-f3eb-488a-a09a-b8a09522e32b"
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습 불필요\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 세트 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}